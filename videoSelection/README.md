# Video properties and balancing

Part of the project involved analyzing visual regions that processed low-level visual features. To reduce the possibility of having a visual property covariating with one of the categories, I decided to create sets of videos for each category that were balanced

After collecting videos that included cats, dogs, humans or cars. I cut the videos into short fragments that lasted between 3.5 and 5.5 s. To reduce the possibility of having a category unbalanced in some low-level visual property, I measured the hue, saturation, brightness, contrast and motion of every video. [This is the code to do that](/calculateVideoValues.m). I also manually coded whether there was a face or not in each video frame in the cat, dog and human videos. For each run, I created video groups for each category using all possible combinations of videos. I selected a group from each category such that there was no across-category visual difference among the visual features measured and that in half of the total video time for each category there was a face.
